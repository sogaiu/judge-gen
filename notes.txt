# USAGE PATTERNS:
#
# * exploratory tests for one's project
# * examples for one's project
# * standalone repository of examples for another project
# * standalone repository of tests for some project -- idea of not
#   including tests in one's project, but rather have them be in a dedicated
#   project for testing.
#   * might be good from a license perspective (tests have a different license)
# * Saikyun's tutorials idea

# LIMITS:
#
# * designed to work using source / examples that live in direct
#   subdirectories of the project directory.  files can be in deeper
#   directories.  see details below for more in-depth explanation.
#
# * doesn't clean up temporary files and directories automatically, though
#   running a subsequent set of tests usually erases old results and
#   generated tests.

# PERIODIC:
#
# * go through code looking for longish functions and consider whether
#   breaking into pieces is a good idea
#
# * go through code looking for XXX and collect here
#
# * audit / review code for:
#   * use of stdout vs stderr (e.g. prin* vs eprin*)
#   * prefer break over assert in many places?
#   * break without argument
#   * once error-handling approach is settled on, try to follow it

# POSSIBILITIES:
#
# * make a version of judge-gen that forces a particular subdirectory
#   name, e.g. `usages`.  this might provide a simpler starting point.
#
# * add auto-create of judge-root if doesn't exist?
#
# * fun logo or blurb?
#
# * not having names for some things is turning out to be awkward.
#   specifically for:
#   * name of the directory used as a source of info to generate tests
#     (contains source)
#   * name of the generated directory that contains a copy of the source
#     files and directories as well as generated tests, and results + output
#   however, the unnecessary creation of new names increase clutter,
#   time-to-comprehension, etc.  in this case we might choose to use
#   the argument names of `judges/make-judges`.  it might make sense
#   to change those names to make them more suitable for disucssion.
#   atm they are `src-root` and `judge-root` (full-path versions).
#   the name portion of `judge-root` is referred to as `judge-dir-name`.
#
# * document one or more cases that show the problem of not choosing
#   a direct subdirectory as a source for generating tests?
#   one case is...suppose there is a direct subdirectory of the project
#   directory named `src`.  suppose there are two subdirectories
#   `src/a` and `src/b`.  suppose also that some source files in `src/a`
#   refer to sources files in `src/b` using `import` with a relative path.
#   if only the content of `src/a` were to be copied to be used by
#   generated tests, the `import` forms that reference `src/b` files
#   relatively would fail because those files would not exist at the
#   appropriate locations within the destination directory.
#
# * consider documenting the `:judge-gen/test-out` dynamic variable.  here
#   are some ways it is involved in code:
#   * when the runner executes a test file, it is set
#   * _verify/dump-results checks it to decide how to outut results
#   * it is checked in `main.janet` to decide whether to execute the runner
#   is it possible to use an environment variable (or multiple) appropriately
#   instead of a dynamic variable?
#
# * try to spell out criteria for making a tagged release
#   * up-to-date docs
#   * ensure tests pass on the 3 common platforms
#   * verify works correctly with existing repositories:
#     * clojure-peg
#     * detect-clj-ns
#     * forcett
#     * janet-bits
#     * janet-peg
#     * janet-xmlish
#     * janet-zip
#     * judge-gen
#     * mal-peg
#     * margaret
#
# * document installation method of placing a symlink from some file in
#   `test` to a single judge-gen.janet file elsewhere (e.g. in `support`).
#   seems like this makes it possible to use a single underlying runner
#   via multiple locations (i.e. use multiple symlinks to it).
#
# * consider other ways to end up with a single file which `jpm test`
#   will execute:
#   * investigate `.jimage` and janet's `-c` command line option.  could
#     this somehow be another route to a single-file output?
#   * could jpm's quickbin result be renamed to have `.janet` file
#     extension?
#   both of the above options would close off the ability to edit the
#   runner.  presumably it would still be possible to rebuild a new runner
#   after editing source.
#
# * consider controlling behavior via env vars -- e.g. disable running.
#   then each user is free to make multiple launch scripts that set env vars
#   before executing `jpm test`
#   * lauching via a script has another potential benefit which is
#     that additional command line options can be meaningfully
#     specified as `jpm test` doesn't allow for passing additional
#     command line arguments.
#   * benefit over command line arguments here is two-fold:
#     * works with `jpm test`
#     * don't have to think about names for subcommands, options, etc.
#   * a drawback might be security-related -- if there is no way to
#     indicate ignoring env vars
#
# * would using recent janet-peg for parsing as well as rewriting
#   source be any better than the current approach?
#   * possibly easier to transform and output (assuming something like
#     janet-zip or similar exists?)
#     * semantics of "judge-" file may more closely match intent if
#       comment blocks are unwrapped "inline", though it's also possible
#       that people might not have considered the impacts of evaluating
#       the content of one comment block vs another (e.g. use of the same
#       names)
#     * alternative output formats of tests (e.g. helper.janet, testament,
#       etc.) / conversion might be easier with this approach?
#   * possibly easier to determine line / column info for tests?
#   * examine alc.x-as-tests for hints
#
# * consider what might be done to improve error handling and messages
#   * track and log actual instances
#   * use `file/flush` and friends (e.g. `eflush`) appropriately to get
#     messages to show up in proper order
#   * use convention of capitalizing first word of ordinary stderr output
#     and lowercase first word of `(dyn :debug)` messages?
#     alternatively, prefix debug output with something like "[debug]"
#   * consider whether the following approach is sensible:
#     * use `(error nil)` when producing output is no longer neceesary
#       (i.e. already done), but it's still an error.
#     * use `(error {...})` to pass info back "up" to eventually have
#       the info used in an appropriate message
#     * compare with idea:
#       * in generate/handle_one, instead of `(break false)`, perhaps different
#         values could be returned to indicate different types of errors
#
# * try to "finish" judge-gen and not add anything as much as possible
#   * be able to launch in debug mode (via `:args`) for additional output?
#   * consider an extension mechanism where some extensions are only
#     run via direct execution of the runner:
#     `janet test/runner.janet --extension` (cf. `(dyn :args)`)
#     * may be it's good to have hook "points" in the existing code
#       where extensions can be called from.
#     * some ideas
#       * possible to provide config file / directory via extension?
#       * linting source files via extension?
#       * diagnostic mode might be done to check sanity of file / directory
#         structure, etc. via extension? collect gotchas, issues, etc.
#         together for consideration of potential things to check for.
#       * trying to run all test files to determine every file that leads
#         to failure (cf. `jpm test` fail early behavior gives an incomplete
#         picture) via extension?
#       * customizing reporting might be implemented via extension?
#       * various "rewriting" targets, e.g. testament, helper.janet
#         for "transition" / exporting purposes
#       * a mode of operation to work on stuff outside a comment block?
#
#         so for example the following at the top-level:
#
#           (def a 1)
#           # => 1
#
#        ought to work as input to generate's transformation process.
#      * a mode of operation to apply runner to a single file
#      * consider different reporting modes.  concrete examples:
#        * for earliest / quickest feedback, have _verify output info as soon
#          as it is available
#        * for slower feedback, have _verify just pass back all test
#          results at the end when they are all ready
#        different receivers might be set up for handling test results, but
#        this may be getting too elaborate at this stage :)
#
# * document the limitation about direct subdirectories of the project
#   directory and the "why".  a direct subdirectory of the project directory
#   has at least the following important properties:
#   * copying the content (contained files and directories) to a sibling
#     directory (one that is also a direct subdirectory of the
#     project directory) doesn't adversely affect most likely (tm)
#     paths in import forms.  at least so far, the probability of
#     the imports still working after copying seems pretty high.
#     one pathological case is an import with the path of the form
#     "../name-a/name-b", where the import is in a file which lives in
#     a directory with name "name-a".  things like this are likely to
#     not work with judge-gen's copying scheme.  it seems unlikely to
#     be a problem though because why wouldn't one express the path
#     like "./name-b" instead?
#   * copying the content (contained files and directories) to a sibling
#     directory also doesn't "leave behind" files and directories that might
#     be necessary for imports to work correctly.  if a non-direct
#     subdirectory of the project directory is specified, there is a chance
#     its content will refer to a sibling's content (which would also be a
#     non-direct subdirectory of the project directory), and judge-gen's
#     copying scheme would fail for this case.
#   if these two points are not issues for one's use case, it may be
#   that one could use a non-direct subdirectory of the project directory
#   (i.e. a "deeper" subdirectory) without issues.  however, at present it
#   is likely to require source-level changes.
#
# * _verify/dump-results uses "%p" in a branch.  determine if this could
#   be a problem but also whether this branch is ever used.
#
# * downside of using `(deep= A B)` with expected value of true is
#   when the test fails, there's not a whole lot of useful information
#   apart from the failure.  is this just a trade-off that has to be
#   made with the current approach?  there is a way to write things
#   that avoids this, but that method requires writing a `def` before
#   the expression to be evaluated and then using the name of the
#   `def` as the expected value.  might be good to add this type of info
#   to documentation.
#
# * consider if there is any benefit in allowing some control over
#   test file execution order, e.g.
#   * sort by name
#   * sort by other criteria
#   * random
#   * custom order
#
# * consider reporting number of tests per file

# ISSUES:
#
# * how / whether to handle rather large return values -- load from external
#   file?
#
# * how / whether to try to test output (such as from `print`) -- see
#   spork's `capture-stdout` for an idea
#
# * some existing repositories use an older version of judge-gen, enumerate
#   these and consider migration to newer version.  some things that might
#   need to be done:
#   * count number of tests using old version of judge-gen
#   * ensure tests only use simplified syntax
#   * edit project.janet to remove stale phony targets
#   * add runner to test directory
#   * compare number of tests between old and new versions
#   * possibly remove jg and jg-verdict binaries
